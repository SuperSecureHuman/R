{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"R I'll be documenting some R stuff as I learn them. R Basics Basics of R page I followed this course on EdX - Data Science: R Basics Data Visualization Data Visualization page EdX course - Data Science: Visualization","title":"R"},{"location":"#r","text":"I'll be documenting some R stuff as I learn them.","title":"R"},{"location":"#r-basics","text":"Basics of R page I followed this course on EdX - Data Science: R Basics","title":"R Basics"},{"location":"#data-visualization","text":"Data Visualization page EdX course - Data Science: Visualization","title":"Data Visualization"},{"location":"0.R-Linux/","text":"Setting up R Arch Linux (BTW) To use R on VsCode, you need: VSCode (duh?) R (Install from Pacman repo) R Extention for VS code (https://marketplace.visualstudio.com/items?itemName=Ikuyadeu.r) R debugger (https://marketplace.visualstudio.com/items?itemName=RDebugger.r-debugger) R Tools - optional - (https://marketplace.visualstudio.com/items?itemName=Mikhail-Arkhipov.r) Note: To run R Tools, you need dotnet 5.0. This is available on the AUR, and it will work just fine Using R Studio for R is recommneded, because of its IDE features. You can use rstudio-desktop-bin from aur for this. I will be using DataSpell By Jetbrains for this. I like this IDE, even though it eats ram :sweat_smile: You have to install dslabs package - install.packages(\"dslabs\") - To ensure repatablity of the code.","title":"Setting up R Arch Linux (BTW)"},{"location":"0.R-Linux/#setting-up-r-arch-linux-btw","text":"To use R on VsCode, you need: VSCode (duh?) R (Install from Pacman repo) R Extention for VS code (https://marketplace.visualstudio.com/items?itemName=Ikuyadeu.r) R debugger (https://marketplace.visualstudio.com/items?itemName=RDebugger.r-debugger) R Tools - optional - (https://marketplace.visualstudio.com/items?itemName=Mikhail-Arkhipov.r) Note: To run R Tools, you need dotnet 5.0. This is available on the AUR, and it will work just fine Using R Studio for R is recommneded, because of its IDE features. You can use rstudio-desktop-bin from aur for this. I will be using DataSpell By Jetbrains for this. I like this IDE, even though it eats ram :sweat_smile: You have to install dslabs package - install.packages(\"dslabs\") - To ensure repatablity of the code.","title":"Setting up R Arch Linux (BTW)"},{"location":"Basics/","text":"Basics of R Contents 01 - Starting with R 02 - Vectors and Sorting 03 - Playing with data 04 - Scripting and progamming with R Additiional Referneces Introduction to Data Science - Data Analysis and Prediction Algorithms with R Data Science: R Basics - Course on EdX","title":"Basics of R"},{"location":"Basics/#basics-of-r","text":"","title":"Basics of R"},{"location":"Basics/#contents","text":"01 - Starting with R 02 - Vectors and Sorting 03 - Playing with data 04 - Scripting and progamming with R","title":"Contents"},{"location":"Basics/#additiional-referneces","text":"Introduction to Data Science - Data Analysis and Prediction Algorithms with R Data Science: R Basics - Course on EdX","title":"Additiional Referneces"},{"location":"Basics/01%20-%20Starting%20with%20R/","text":"Starting with R R in DataSpell When you run a script, the IDE will run the script line by line on the console. If it has some graphics, the IDE will display them. Along with it, you get a pane, where you can browse the workspace's variables and stuff. Assigning something to a variable a <- 1 b <- -1 # Here, we just assigned a to be 1, and b to be -1. We can also use = to assign a value to a variable, but its recommended not to use it. Example of solving the quadratic formula in R Functions Earlier we used sqrt() which is a function. Functions are either built in, brought in from libraries, or defined by the user. If you dont use () it instead prints the code for the function, rather than using the function. Most functions require atleat 1 arguments. You can see the same in here Sample_Script Data types in R Function class() helps us to find the data type of some object. > a <- 1 > class ( a ) [ 1 ] \"numeric\" Using a data set Note - We will be using dslabs to get our data set. > library ( dslabs ) > data ( murders ) # Now we will check class of this data set > class ( \"murders\" ) [ 1 ] \"data.frame\" str() function We use str() to find the structure of a dateframe. > str ( murders ) 'data.frame' : 51 obs. of 5 variables : $ state : chr \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ... $ abb : chr \"AL\" \"AK\" \"AZ\" \"AR\" ... $ region : Factor w / 4 levels \"Northeast\" , \"South\" , .. : 2 4 4 2 4 4 1 2 2 2 ... $ population : num 4779736 710231 6392017 2915918 37253956 ... $ total : num 135 19 232 93 1257 ... #The first line says that this is a dataframe with 51 observations and 5 features. # The following lines preview few elements of that feature along with its data type ``` If you notice, the region has the data type `Factor`. This is used to store categorical data. Like 1 maps to 'A', 2 maps to 'B' and so on. This is mostly because of memory management. It dosent matter for small data sets like this. But when it comes to larger data sets, it counts ### Accessing the data inside a dataframe To access a column, we use ` $ ` followed by the column name. For example ```R > data ( murders ) > str ( murders ) 'data.frame' : 51 obs. of 5 variables : $ state : chr \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ... $ abb : chr \"AL\" \"AK\" \"AZ\" \"AR\" ... $ region : Factor w / 4 levels \"Northeast\" , \"South\" , .. : 2 4 4 2 4 4 1 2 2 2 ... $ population : num 4779736 710231 6392017 2915918 37253956 ... $ total : num 135 19 232 93 1257 ... > murders $ population [ 1 ] 4779736 710231 6392017 2915918 37253956 5029196 3574097 897934 601723 19687653 9920000 1360301 1567582 12830632 6483802 3046355 [ 17 ] 2853118 4339367 4533372 1328361 5773552 6547629 9883640 5303925 2967297 5988927 989415 1826341 2700551 1316470 8791894 2059179 [ 33 ] 19378102 9535483 672591 11536504 3751351 3831074 12702379 1052567 4625364 814180 6346105 25145561 2763885 625741 8001024 6724540 [ 49 ] 1852994 5686986 563626 Using names function to get features in a data set (It returns the names of the columns) > names ( murders ) [ 1 ] \"state\" \"abb\" \"region\" \"population\" \"total\" Creating a Data Frame You can create a data frame using the data.frame function. Here is a quick example: temp <- c ( 35 , 88 , 42 , 84 , 81 , 30 ) city <- c ( \"Beijing\" , \"Lagos\" , \"Paris\" , \"Rio de Janeiro\" , \"San Juan\" , \"Toronto\" ) city_temps <- data.frame ( name = city , temperature = temp ) Bunch of code for you to try out # loading the dslabs package and the murders dataset library ( dslabs ) data ( murders ) # determining that the murders dataset is of the \"data frame\" class class ( murders ) # finding out more about the structure of the object str ( murders ) # showing the first 6 lines of the dataset head ( murders ) # using the accessor operator to obtain the population column murders $ population # displaying the variable names in the murders dataset names ( murders ) # determining how many entries are in a vector pop <- murders $ population length ( pop ) # vectors can be of class numeric and character class ( pop ) class ( murders $ state ) # logical vectors are either TRUE or FALSE z <- 3 == 2 z class ( z ) # factors are another type of class class ( murders $ region ) # obtaining the levels of a factor levels ( murders $ region )","title":"Starting with R"},{"location":"Basics/01%20-%20Starting%20with%20R/#starting-with-r","text":"","title":"Starting with R"},{"location":"Basics/01%20-%20Starting%20with%20R/#r-in-dataspell","text":"When you run a script, the IDE will run the script line by line on the console. If it has some graphics, the IDE will display them. Along with it, you get a pane, where you can browse the workspace's variables and stuff.","title":"R in DataSpell"},{"location":"Basics/01%20-%20Starting%20with%20R/#assigning-something-to-a-variable","text":"a <- 1 b <- -1 # Here, we just assigned a to be 1, and b to be -1. We can also use = to assign a value to a variable, but its recommended not to use it. Example of solving the quadratic formula in R","title":"Assigning something to a variable"},{"location":"Basics/01%20-%20Starting%20with%20R/#functions","text":"Earlier we used sqrt() which is a function. Functions are either built in, brought in from libraries, or defined by the user. If you dont use () it instead prints the code for the function, rather than using the function. Most functions require atleat 1 arguments. You can see the same in here Sample_Script","title":"Functions"},{"location":"Basics/01%20-%20Starting%20with%20R/#data-types-in-r","text":"Function class() helps us to find the data type of some object. > a <- 1 > class ( a ) [ 1 ] \"numeric\"","title":"Data types in R"},{"location":"Basics/01%20-%20Starting%20with%20R/#using-a-data-set","text":"Note - We will be using dslabs to get our data set. > library ( dslabs ) > data ( murders ) # Now we will check class of this data set > class ( \"murders\" ) [ 1 ] \"data.frame\"","title":"Using a data set"},{"location":"Basics/01%20-%20Starting%20with%20R/#str-function","text":"We use str() to find the structure of a dateframe. > str ( murders ) 'data.frame' : 51 obs. of 5 variables : $ state : chr \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ... $ abb : chr \"AL\" \"AK\" \"AZ\" \"AR\" ... $ region : Factor w / 4 levels \"Northeast\" , \"South\" , .. : 2 4 4 2 4 4 1 2 2 2 ... $ population : num 4779736 710231 6392017 2915918 37253956 ... $ total : num 135 19 232 93 1257 ... #The first line says that this is a dataframe with 51 observations and 5 features. # The following lines preview few elements of that feature along with its data type ``` If you notice, the region has the data type `Factor`. This is used to store categorical data. Like 1 maps to 'A', 2 maps to 'B' and so on. This is mostly because of memory management. It dosent matter for small data sets like this. But when it comes to larger data sets, it counts ### Accessing the data inside a dataframe To access a column, we use ` $ ` followed by the column name. For example ```R > data ( murders ) > str ( murders ) 'data.frame' : 51 obs. of 5 variables : $ state : chr \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ... $ abb : chr \"AL\" \"AK\" \"AZ\" \"AR\" ... $ region : Factor w / 4 levels \"Northeast\" , \"South\" , .. : 2 4 4 2 4 4 1 2 2 2 ... $ population : num 4779736 710231 6392017 2915918 37253956 ... $ total : num 135 19 232 93 1257 ... > murders $ population [ 1 ] 4779736 710231 6392017 2915918 37253956 5029196 3574097 897934 601723 19687653 9920000 1360301 1567582 12830632 6483802 3046355 [ 17 ] 2853118 4339367 4533372 1328361 5773552 6547629 9883640 5303925 2967297 5988927 989415 1826341 2700551 1316470 8791894 2059179 [ 33 ] 19378102 9535483 672591 11536504 3751351 3831074 12702379 1052567 4625364 814180 6346105 25145561 2763885 625741 8001024 6724540 [ 49 ] 1852994 5686986 563626","title":"str() function"},{"location":"Basics/01%20-%20Starting%20with%20R/#using-names-function-to-get-features-in-a-data-set-it-returns-the-names-of-the-columns","text":"> names ( murders ) [ 1 ] \"state\" \"abb\" \"region\" \"population\" \"total\"","title":"Using names function to get features in a data set (It returns the names of the columns)"},{"location":"Basics/01%20-%20Starting%20with%20R/#creating-a-data-frame","text":"You can create a data frame using the data.frame function. Here is a quick example: temp <- c ( 35 , 88 , 42 , 84 , 81 , 30 ) city <- c ( \"Beijing\" , \"Lagos\" , \"Paris\" , \"Rio de Janeiro\" , \"San Juan\" , \"Toronto\" ) city_temps <- data.frame ( name = city , temperature = temp )","title":"Creating a Data Frame"},{"location":"Basics/01%20-%20Starting%20with%20R/#bunch-of-code-for-you-to-try-out","text":"# loading the dslabs package and the murders dataset library ( dslabs ) data ( murders ) # determining that the murders dataset is of the \"data frame\" class class ( murders ) # finding out more about the structure of the object str ( murders ) # showing the first 6 lines of the dataset head ( murders ) # using the accessor operator to obtain the population column murders $ population # displaying the variable names in the murders dataset names ( murders ) # determining how many entries are in a vector pop <- murders $ population length ( pop ) # vectors can be of class numeric and character class ( pop ) class ( murders $ state ) # logical vectors are either TRUE or FALSE z <- 3 == 2 z class ( z ) # factors are another type of class class ( murders $ region ) # obtaining the levels of a factor levels ( murders $ region )","title":"Bunch of code for you to try out"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/","text":"Vectors Vectors is the basic unit in R. Creating Vectors One way to create vectors is to use the c function. # We may create vectors of class numeric or character with the concatenate function codes <- c ( 380 , 124 , 818 ) country <- c ( \"italy\" , \"canada\" , \"egypt\" ) # We can also name the elements of a numeric vector # Note that the two lines of code below have the same result codes <- c ( italy = 380 , canada = 124 , egypt = 818 ) codes <- c ( \"italy\" = 380 , \"canada\" = 124 , \"egypt\" = 818 ) # We can also name the elements of a numeric vector using the names() function codes <- c ( 380 , 124 , 818 ) country <- c ( \"italy\" , \"canada\" , \"egypt\" ) names ( codes ) <- country #Remember that the class `codes` will continue to be a numeric vector, even though it has been labeled Creating Sequences We use seq() to generate number sequences. The syntax is: seq(start, stop, step) start : the first number in the sequence stop : the last number in the sequence step : the step size between numbers in the sequence Note: If you want consecutive numbers, use can use this shortcut 1:10 --> start:stop Accessing Elements in a Vector We use [] to access stuff in vectors # Using square brackets is useful for subsetting to access specific elements of a vector codes [ 2 ] codes [ c ( 1 , 3 )] codes [ 1 : 2 ] # If the entries of a vector are named, they may be accessed by referring to their name codes [ \"canada\" ] codes [ c ( \"egypt\" , \"italy\" )] The seq() function has another useful argument. The argument length.out. This argument lets us generate sequences that are increasing by the same amount but are of the prespecified length. For example, this line of code x <- seq ( 0 , 100 , length.out = 5 ) produces the numbers 0, 25, 50, 75, 100 . Vector Coercion When we define a vector, but with non-same data types, R tries to guess the data type of the elements. Look at the following example to get more idea on this. > x <- c ( 1 , \"canada\" , 3 ) > x [ 1 ] \"1\" \"canada\" \"3\" Here, the variable x included char and int. But when storing the variable, it took all as strings Forcing Coercion You can use as.character() to force the coercion of a vector to character. > x <- 0 : 10 > y <- as.character ( x ) > y [ 1 ] \"0\" \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\" \"9\" \"10\" > class ( y ) [ 1 ] \"character\" Sorting We will be using the murder dataset here. sort() by default sorts them in ascending order library ( dslabs ) data ( murders ) sort ( murders $ total ) > [ 1 ] 2 4 5 5 7 8 11 12 12 16 19 21 22 27 32 36 38 53 63 65 67 84 93 93 97 97 99 111 116 [ 30 ] 118 120 135 142 207 219 232 246 250 286 293 310 321 351 364 376 413 457 517 669 805 1257 order() function returns the indices that is sorted by the given parameter. > x <- c ( 31 , 4 , 15 , 92 , 65 ) > sort ( x ) [ 1 ] 4 15 31 65 92 > index <- order ( x ) > x [ index ] [ 1 ] 4 15 31 65 92 > order ( x ) [ 1 ] 2 3 1 5 4 Vector Arithmetic Arithematic operations are performed elemntwise in R. Now we will try calculateing murder rate with the help of our dataset # The name of the state with the maximum population is found by doing the following murders $ state [ which.max ( murders $ population )] # how to obtain the murder rate murder_rate <- murders $ total / murders $ population * 100000 # ordering the states by murder rate, in decreasing order murders $ state [ order ( murder_rate , decreasing = TRUE )]","title":"Vectors"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/#vectors","text":"Vectors is the basic unit in R.","title":"Vectors"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/#creating-vectors","text":"One way to create vectors is to use the c function. # We may create vectors of class numeric or character with the concatenate function codes <- c ( 380 , 124 , 818 ) country <- c ( \"italy\" , \"canada\" , \"egypt\" ) # We can also name the elements of a numeric vector # Note that the two lines of code below have the same result codes <- c ( italy = 380 , canada = 124 , egypt = 818 ) codes <- c ( \"italy\" = 380 , \"canada\" = 124 , \"egypt\" = 818 ) # We can also name the elements of a numeric vector using the names() function codes <- c ( 380 , 124 , 818 ) country <- c ( \"italy\" , \"canada\" , \"egypt\" ) names ( codes ) <- country #Remember that the class `codes` will continue to be a numeric vector, even though it has been labeled","title":"Creating Vectors"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/#creating-sequences","text":"We use seq() to generate number sequences. The syntax is: seq(start, stop, step) start : the first number in the sequence stop : the last number in the sequence step : the step size between numbers in the sequence Note: If you want consecutive numbers, use can use this shortcut 1:10 --> start:stop","title":"Creating Sequences"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/#accessing-elements-in-a-vector","text":"We use [] to access stuff in vectors # Using square brackets is useful for subsetting to access specific elements of a vector codes [ 2 ] codes [ c ( 1 , 3 )] codes [ 1 : 2 ] # If the entries of a vector are named, they may be accessed by referring to their name codes [ \"canada\" ] codes [ c ( \"egypt\" , \"italy\" )] The seq() function has another useful argument. The argument length.out. This argument lets us generate sequences that are increasing by the same amount but are of the prespecified length. For example, this line of code x <- seq ( 0 , 100 , length.out = 5 ) produces the numbers 0, 25, 50, 75, 100 .","title":"Accessing Elements in a Vector"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/#vector-coercion","text":"When we define a vector, but with non-same data types, R tries to guess the data type of the elements. Look at the following example to get more idea on this. > x <- c ( 1 , \"canada\" , 3 ) > x [ 1 ] \"1\" \"canada\" \"3\" Here, the variable x included char and int. But when storing the variable, it took all as strings","title":"Vector Coercion"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/#forcing-coercion","text":"You can use as.character() to force the coercion of a vector to character. > x <- 0 : 10 > y <- as.character ( x ) > y [ 1 ] \"0\" \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\" \"9\" \"10\" > class ( y ) [ 1 ] \"character\"","title":"Forcing Coercion"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/#sorting","text":"We will be using the murder dataset here. sort() by default sorts them in ascending order library ( dslabs ) data ( murders ) sort ( murders $ total ) > [ 1 ] 2 4 5 5 7 8 11 12 12 16 19 21 22 27 32 36 38 53 63 65 67 84 93 93 97 97 99 111 116 [ 30 ] 118 120 135 142 207 219 232 246 250 286 293 310 321 351 364 376 413 457 517 669 805 1257 order() function returns the indices that is sorted by the given parameter. > x <- c ( 31 , 4 , 15 , 92 , 65 ) > sort ( x ) [ 1 ] 4 15 31 65 92 > index <- order ( x ) > x [ index ] [ 1 ] 4 15 31 65 92 > order ( x ) [ 1 ] 2 3 1 5 4","title":"Sorting"},{"location":"Basics/02%20-%20Vectors%2C%20Sorting/#vector-arithmetic","text":"Arithematic operations are performed elemntwise in R. Now we will try calculateing murder rate with the help of our dataset # The name of the state with the maximum population is found by doing the following murders $ state [ which.max ( murders $ population )] # how to obtain the murder rate murder_rate <- murders $ total / murders $ population * 100000 # ordering the states by murder rate, in decreasing order murders $ state [ order ( murder_rate , decreasing = TRUE )]","title":"Vector Arithmetic"},{"location":"Basics/03%20-%20Playing%20With%20Data/","text":"Indexing in R R has powerful tools to perform indexing. We will see an example, on how easy it is to filter out states with certain thresholds of murder rate. Note: In R, vectors can be indexed with logicals. This means, when an index says 'TRUE' the vector is indexed. We will be using this in the upcomming example # defining murder rate as before murder_rate <- murders $ total / murders $ population * 100000 # creating a logical vector that specifies if the murder rate in that state is less than or equal to 0.71 index <- murder_rate <= 0.71 # determining which states have murder rates less than or equal to 0.71 murders $ state [ index ] # calculating how many states have a murder rate less than or equal to 0.71 sum ( index ) Some functions in indexing We will look at 3 functions used in indexing. They are which , match , and %in% . which() gives returns a vector, with the index value of TRUE in the input vector. x <- c ( FALSE , TRUE , FALSE , TRUE , TRUE , FALSE ) which ( x ) # returns indices that are TRUE [ 1 ] 2 4 5 match() looks for entries in a vector and returns the index needed to access them. index <- match ( c ( \"New York\" , \"Florida\" , \"Texas\" ), murders $ state ) index murders $ state [ index ] murder_rate [ index ] %in% function checks if one array is the subset of another array Data Wrangling We will be using dplyer package here. Make sure to install them. This packages provides some basic data manuplation functions, with easy to remember names mutate() is used to add columns to our data set. murders <- mutate ( murders , rate = total / population * 100000 ) You can check first few rows of the data set by using head() function. filter() is used to filter out data based on a condition. filter ( murders , rate <= 0.71 ) select() is used to select a subset of data based on column names. new_table <- select ( murders , state , region , rate ) filter ( new_table , rate <= 0.71 ) The pipe operator %>% The %>% operator is used to chain together functions. Lets see an example, where we are gonna filter out states with certain murder rate. murders %>% select ( state , region , rate ) %>% filter ( rate <= 0.71 ) Creating Data Frames Creating dataframes is straight forward in R. Look at the following example # creating a data frame with stringAsFactors = FALSE grades <- data.frame ( names = c ( \"John\" , \"Juan\" , \"Jean\" , \"Yao\" ), exam_1 = c ( 95 , 80 , 90 , 85 ), exam_2 = c ( 90 , 85 , 85 , 90 ), stringsAsFactors = FALSE ) Formerly, the data.frame() function turned characters into factors by default. To avoid this, we could utilize the stringsAsFactors argument and set it equal to false. As of R 4.0, it is no longer necessary to include the stringsAsFactors argument, because R no longer turns characters into factors by default. Plotting Plotting with the inbuilt function is straight forward in R. You just call the function and pass the data you want to plot. Lets see an simple example. library ( dplyr ) library ( dslabs ) data ( \"murders\" ) # a simple scatterplot of total murders versus population x <- murders $ population / 10 ^ 6 y <- murders $ total plot ( x , y ) Similary, we can plot histogram and box plots # a histogram of murder rates murders <- mutate ( murders , rate = total / population * 100000 ) hist ( murders $ rate ) # boxplots of murder rates by region boxplot ( rate ~ region , data = murders ) Here is the histogram Here is the box plot","title":"Index"},{"location":"Basics/03%20-%20Playing%20With%20Data/#indexing-in-r","text":"R has powerful tools to perform indexing. We will see an example, on how easy it is to filter out states with certain thresholds of murder rate. Note: In R, vectors can be indexed with logicals. This means, when an index says 'TRUE' the vector is indexed. We will be using this in the upcomming example # defining murder rate as before murder_rate <- murders $ total / murders $ population * 100000 # creating a logical vector that specifies if the murder rate in that state is less than or equal to 0.71 index <- murder_rate <= 0.71 # determining which states have murder rates less than or equal to 0.71 murders $ state [ index ] # calculating how many states have a murder rate less than or equal to 0.71 sum ( index )","title":"Indexing in R"},{"location":"Basics/03%20-%20Playing%20With%20Data/#some-functions-in-indexing","text":"We will look at 3 functions used in indexing. They are which , match , and %in% . which() gives returns a vector, with the index value of TRUE in the input vector. x <- c ( FALSE , TRUE , FALSE , TRUE , TRUE , FALSE ) which ( x ) # returns indices that are TRUE [ 1 ] 2 4 5 match() looks for entries in a vector and returns the index needed to access them. index <- match ( c ( \"New York\" , \"Florida\" , \"Texas\" ), murders $ state ) index murders $ state [ index ] murder_rate [ index ] %in% function checks if one array is the subset of another array","title":"Some functions in indexing"},{"location":"Basics/03%20-%20Playing%20With%20Data/#data-wrangling","text":"We will be using dplyer package here. Make sure to install them. This packages provides some basic data manuplation functions, with easy to remember names mutate() is used to add columns to our data set. murders <- mutate ( murders , rate = total / population * 100000 ) You can check first few rows of the data set by using head() function. filter() is used to filter out data based on a condition. filter ( murders , rate <= 0.71 ) select() is used to select a subset of data based on column names. new_table <- select ( murders , state , region , rate ) filter ( new_table , rate <= 0.71 )","title":"Data Wrangling"},{"location":"Basics/03%20-%20Playing%20With%20Data/#the-pipe-operator","text":"The %>% operator is used to chain together functions. Lets see an example, where we are gonna filter out states with certain murder rate. murders %>% select ( state , region , rate ) %>% filter ( rate <= 0.71 )","title":"The pipe operator %&gt;%"},{"location":"Basics/03%20-%20Playing%20With%20Data/#creating-data-frames","text":"Creating dataframes is straight forward in R. Look at the following example # creating a data frame with stringAsFactors = FALSE grades <- data.frame ( names = c ( \"John\" , \"Juan\" , \"Jean\" , \"Yao\" ), exam_1 = c ( 95 , 80 , 90 , 85 ), exam_2 = c ( 90 , 85 , 85 , 90 ), stringsAsFactors = FALSE ) Formerly, the data.frame() function turned characters into factors by default. To avoid this, we could utilize the stringsAsFactors argument and set it equal to false. As of R 4.0, it is no longer necessary to include the stringsAsFactors argument, because R no longer turns characters into factors by default.","title":"Creating Data Frames"},{"location":"Basics/03%20-%20Playing%20With%20Data/#plotting","text":"Plotting with the inbuilt function is straight forward in R. You just call the function and pass the data you want to plot. Lets see an simple example. library ( dplyr ) library ( dslabs ) data ( \"murders\" ) # a simple scatterplot of total murders versus population x <- murders $ population / 10 ^ 6 y <- murders $ total plot ( x , y ) Similary, we can plot histogram and box plots # a histogram of murder rates murders <- mutate ( murders , rate = total / population * 100000 ) hist ( murders $ rate ) # boxplots of murder rates by region boxplot ( rate ~ region , data = murders ) Here is the histogram Here is the box plot","title":"Plotting"},{"location":"Basics/04%20-%20Scripting%2C%20Programming%20with%20R/","text":"Programming in R Here, we will go through 3 main programming concepts - conditionals, for-loops and functions. Conditionals Lets try a basic if-else block. # Define a variable a <- 0 # if a is not equal to 0, print the inverse of a if ( a != 0 ){ print ( 1 / a ) } # if the prev check failed (ie a = 0), the else statement will be executed else { print ( \"No reciprocal for 0.\" ) } The ifelse() block in R is powerfull. It takes in 3 args - the condition, the true statement and the false statement. This can be really powerful when used on vectors # the ifelse() function works similarly to an if-else conditional a <- 0 ifelse ( a > 0 , 1 / a , NA ) # the ifelse() function is particularly useful on vectors a <- c ( 0 , 1 , 2 , -4 , 5 ) result <- ifelse ( a > 0 , 1 / a , NA ) # the ifelse() function is also helpful for replacing missing values data ( na_example ) no_nas <- ifelse ( is.na ( na_example ), 0 , na_example ) sum ( is.na ( no_nas )) # the any() and all() functions evaluate logical vectors z <- c ( TRUE , TRUE , FALSE ) #Retrurn true if any one is true any ( z ) #Return true only if all are true all ( z ) Functions Lets write a function to compute mean of a data set avg <- function ( x ){ s <- sum ( x ) l <- length ( x ) s / l } #Now you can call avg function, with a vector as input, and it will return the average of the vector For Loops For-loops perform the same task over and over while changing the variable. They let us define the range that our variable takes, and then changes the value with each loop and evaluates the expression every time inside the loop. The general form of a for-loop is: \"For i in [some range], do operations\". This i changes across the range of values and the operations assume i is a value you're interested in computing on. At the end of the loop, the value of i is the last value of the range.","title":"Programming in R"},{"location":"Basics/04%20-%20Scripting%2C%20Programming%20with%20R/#programming-in-r","text":"Here, we will go through 3 main programming concepts - conditionals, for-loops and functions.","title":"Programming in R"},{"location":"Basics/04%20-%20Scripting%2C%20Programming%20with%20R/#conditionals","text":"Lets try a basic if-else block. # Define a variable a <- 0 # if a is not equal to 0, print the inverse of a if ( a != 0 ){ print ( 1 / a ) } # if the prev check failed (ie a = 0), the else statement will be executed else { print ( \"No reciprocal for 0.\" ) } The ifelse() block in R is powerfull. It takes in 3 args - the condition, the true statement and the false statement. This can be really powerful when used on vectors # the ifelse() function works similarly to an if-else conditional a <- 0 ifelse ( a > 0 , 1 / a , NA ) # the ifelse() function is particularly useful on vectors a <- c ( 0 , 1 , 2 , -4 , 5 ) result <- ifelse ( a > 0 , 1 / a , NA ) # the ifelse() function is also helpful for replacing missing values data ( na_example ) no_nas <- ifelse ( is.na ( na_example ), 0 , na_example ) sum ( is.na ( no_nas )) # the any() and all() functions evaluate logical vectors z <- c ( TRUE , TRUE , FALSE ) #Retrurn true if any one is true any ( z ) #Return true only if all are true all ( z )","title":"Conditionals"},{"location":"Basics/04%20-%20Scripting%2C%20Programming%20with%20R/#functions","text":"Lets write a function to compute mean of a data set avg <- function ( x ){ s <- sum ( x ) l <- length ( x ) s / l } #Now you can call avg function, with a vector as input, and it will return the average of the vector","title":"Functions"},{"location":"Basics/04%20-%20Scripting%2C%20Programming%20with%20R/#for-loops","text":"For-loops perform the same task over and over while changing the variable. They let us define the range that our variable takes, and then changes the value with each loop and evaluates the expression every time inside the loop. The general form of a for-loop is: \"For i in [some range], do operations\". This i changes across the range of values and the operations assume i is a value you're interested in computing on. At the end of the loop, the value of i is the last value of the range.","title":"For Loops"},{"location":"Data%20Visualization/","text":"Data Visualization Contents 01 - Intro to visualization and distributions 02 - ggplot2 03 - Dplyr 04 - Case Study Additional Resources Data Science: Visualization - EdX course","title":"Data Visualization"},{"location":"Data%20Visualization/#data-visualization","text":"","title":"Data Visualization"},{"location":"Data%20Visualization/#contents","text":"01 - Intro to visualization and distributions 02 - ggplot2 03 - Dplyr 04 - Case Study","title":"Contents"},{"location":"Data%20Visualization/#additional-resources","text":"Data Science: Visualization - EdX course","title":"Additional Resources"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/","text":"Data types There can be 2 main types of data, that we deal in visualizing: Categorical data are variables that are defined by a small number of groups. Ordinal categorical data have an inherent order to the categories (mild/medium/hot, for example). Non-ordinal categorical data have no order to the categories. Numerical data take a variety of numeric values. Continuous variables can take any value. Discrete variables are limited to sets of specific values. Distribution A distribution is a function or description that shows the possible values of a variable and how often those values occur. Lets try to use a dummy data, and try to see the ratio between 2 categories # load the dataset library ( dslabs ) data ( heights ) # make a table of category proportions prop.table ( table ( heights $ sex )) #Output Female Male 0.2266667 0.7733333 A frequency table is the simplest way to show a categorical distribution. Use prop.table() to convert a table of counts to a frequency table. Barplots display the distribution of categorical variables and are a way to visualize the information in frequency tables. Frequency dist is good for categorical data, but when it comes to continous data, this becomes obselete. This is simply because usually all values are unique, and it dosent make sense to check frequency of a certain value. Here, we use cummlative distribution function. The cumulative distribution function (CDF) is a function that reports the proportion of data below a value 'a' for all values of 'a'. Any continuous dataset has a CDF, not only normal distributions. For example, the male heights data we used in the previous section has this CDF: But, this graph is particularly not intuvitive. So, we use histogram, which gives a lot more info, with a litte loss in data. We will deal about histrogram later on. A histogram divides data into non-overlapping bins of the same size and plots the counts of number of values that fall in that interval. Smooth density plots Smooth density plots can be thought of as histograms where the bin width is extremely or infinitely small. The smoothing function makes estimates of the true continuous trend of the data given the available sample of data points. The degree of smoothness can be controlled by an argument in the plotting function. (We will learn functions for plotting later.) While the histogram is an assumption-free summary, the smooth density plot is shaped by assumptions and choices you make The y-axis is scaled so that the area under the density curve sums to 1. This means that interpreting values on the y-axis is not straightforward. To determine the proportion of data in between two values, compute the area under the smooth density curve in the region between those values. An advantage of smooth densities over histograms is that densities are easier to compare visually. Normal Distribution Normal distributions are the most common type of distribution. They are characterized by a mean and a standard deviation. They are known as gaussian distributions, and bell curve. Rather than having the entire data, we can use a normal distribution to approximate the data. Normal dist function is represented by a formula, which makes it easy to summarize the distribution. The normal distribution: Is centered around one value, the mean Is symmetric around the mean Is defined completely by its mean and standard deviation Always has the same proportion of observations within a given distance of the mean Standard units For data that are approximately normal, standard units describe the number of standard deviations an observation is from the mean. Standard units are denoted by the variable z and are also known as z-scores. The 68-95-99.7 Rule The normal distribution is associated with the 68-95-99.7 rule. This rule describes the probability of observing events within a certain number of standard deviations of the mean. The Normal CDF and pnorm The normal distribution has a mathematically defined CDF which can be computed in R with the function pnorm(). pnorm(a, avg, s) gives the value of the cumulative distribution function F(a) for the normal distribution defined by average avg and standard deviation s. We say that a random quantity is normally distributed with average avg and standard deviation s if the approximation pnorm(a, avg, s) holds for all values of a. If we are willing to use the normal approximation for height, we can estimate the distribution simply from the mean and standard deviation of our values. If we treat the height data as discrete rather than categorical, we see that the data are not very useful because integer values are more common than expected due to rounding. This is called discretization. With rounded data, the normal approximation is particularly useful when computing probabilities of intervals of length 1 that include exactly one integer. Quantiles Quantiles are cutoff points that divide a dataset into intervals with set probabilities. The q th quantile is the value at which q % of the observations are equal to or less than that value. You can use the quantile() function to compute quantiles. #Given a dataset data and desired quantile q, you can find the qth quantile of data with: quantile ( data , q ) Percentiles Percentiles are the quantiles that divide a dataset into 100 intervals each with 1% probability. You can determine all percentiles of a dataset data like this: p <- seq ( 0.01 , 0.99 , 0.01 ) quantile ( data , p ) Quartiles Quartiles divide a dataset into 4 parts each with 25% probability. They are equal to the 25th, 50th and 75th percentiles. The 25th percentile is also known as the 1st quartile, the 50th percentile is also known as the median, and the 75th percentile is also known as the 3rd quartile. The summary() function returns the minimum, quartiles and maximum of a vector. Examples library ( dslabs ) data ( heights ) #Use summary() on the heights$height variable to find the quartiles: summary ( heights $ height ) #Find the percentiles of heights$height: p <- seq ( 0.01 , 0.99 , 0.01 ) percentiles <- quantile ( heights $ height , p ) #Confirm that the 25th and 75th percentiles match the 1st and 3rd quartiles. Note that quantile() returns a named vector. You can access the 25th and 75th percentiles like this (adapt the code for other percentile values): percentiles [ names ( percentiles ) == \"25%\" ] percentiles [ names ( percentiles ) == \"75%\" ] Finding quantiles with qnorm() The qnorm() function gives the theoretical value of a quantile with probability p of observing a value equal to or less than that quantile value given a normal distribution with mean mu and standard deviation sigma: qnorm ( p , mu , sigma ) By default, mu = 0 and sigma = 1. Relation to pnorm The pnorm() function gives the probability that a value from a standard normal distribution will be less than or equal to a z-score value z. Consider: pnorm(-1.96) ~= 0.025 The result of pnorm() is the quantile. Note that: qnorm(0.025) ~= -1.96 qnorm() and pnorm() are inverse functions: pnorm(qnorm(0.025)) = 0.025 Quantile-Quantile Plots Quantile-quantile plots, or QQ-plots, are used to check whether distributions are well-approximated by a normal distribution. We start by defining a series of proportion, for example, p equals 0.05, 0.10, 0.15, up to 0.95. Once this is defined for each p, we determine the value q, so that the proportion of the values in the data below q is p. The q's are referred to as the quantiles. Now we will apply this, to out male heights dataset. 5.Q-Q plots Here, you can see that our data points almost fit a straight line. This futher establishes the fact that our data is well suited as a normal distribution with certain parameters. Boxplots When data do not follow a normal distribution and cannot be succinctly summarized by only the mean and standard deviation, an alternative is to report a five-number summary: range (ignoring outliers) and the quartiles (25th, 50th, 75th percentile). In a boxplot, the box is defined by the 25th and 75th percentiles and the median is a horizontal line through the box. The whiskers show the range excluding outliers, and outliers are plotted separately as individual points. The interquartile range is the distance between the 25th and 75th percentiles. Boxplots are particularly useful when comparing multiple distributions.","title":"Index"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#data-types","text":"There can be 2 main types of data, that we deal in visualizing: Categorical data are variables that are defined by a small number of groups. Ordinal categorical data have an inherent order to the categories (mild/medium/hot, for example). Non-ordinal categorical data have no order to the categories. Numerical data take a variety of numeric values. Continuous variables can take any value. Discrete variables are limited to sets of specific values.","title":"Data types"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#distribution","text":"A distribution is a function or description that shows the possible values of a variable and how often those values occur. Lets try to use a dummy data, and try to see the ratio between 2 categories # load the dataset library ( dslabs ) data ( heights ) # make a table of category proportions prop.table ( table ( heights $ sex )) #Output Female Male 0.2266667 0.7733333 A frequency table is the simplest way to show a categorical distribution. Use prop.table() to convert a table of counts to a frequency table. Barplots display the distribution of categorical variables and are a way to visualize the information in frequency tables. Frequency dist is good for categorical data, but when it comes to continous data, this becomes obselete. This is simply because usually all values are unique, and it dosent make sense to check frequency of a certain value. Here, we use cummlative distribution function. The cumulative distribution function (CDF) is a function that reports the proportion of data below a value 'a' for all values of 'a'. Any continuous dataset has a CDF, not only normal distributions. For example, the male heights data we used in the previous section has this CDF: But, this graph is particularly not intuvitive. So, we use histogram, which gives a lot more info, with a litte loss in data. We will deal about histrogram later on. A histogram divides data into non-overlapping bins of the same size and plots the counts of number of values that fall in that interval.","title":"Distribution"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#smooth-density-plots","text":"Smooth density plots can be thought of as histograms where the bin width is extremely or infinitely small. The smoothing function makes estimates of the true continuous trend of the data given the available sample of data points. The degree of smoothness can be controlled by an argument in the plotting function. (We will learn functions for plotting later.) While the histogram is an assumption-free summary, the smooth density plot is shaped by assumptions and choices you make The y-axis is scaled so that the area under the density curve sums to 1. This means that interpreting values on the y-axis is not straightforward. To determine the proportion of data in between two values, compute the area under the smooth density curve in the region between those values. An advantage of smooth densities over histograms is that densities are easier to compare visually.","title":"Smooth density plots"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#normal-distribution","text":"Normal distributions are the most common type of distribution. They are characterized by a mean and a standard deviation. They are known as gaussian distributions, and bell curve. Rather than having the entire data, we can use a normal distribution to approximate the data. Normal dist function is represented by a formula, which makes it easy to summarize the distribution. The normal distribution: Is centered around one value, the mean Is symmetric around the mean Is defined completely by its mean and standard deviation Always has the same proportion of observations within a given distance of the mean","title":"Normal Distribution"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#standard-units","text":"For data that are approximately normal, standard units describe the number of standard deviations an observation is from the mean. Standard units are denoted by the variable z and are also known as z-scores.","title":"Standard units"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#the-68-95-997-rule","text":"The normal distribution is associated with the 68-95-99.7 rule. This rule describes the probability of observing events within a certain number of standard deviations of the mean.","title":"The 68-95-99.7 Rule"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#the-normal-cdf-and-pnorm","text":"The normal distribution has a mathematically defined CDF which can be computed in R with the function pnorm(). pnorm(a, avg, s) gives the value of the cumulative distribution function F(a) for the normal distribution defined by average avg and standard deviation s. We say that a random quantity is normally distributed with average avg and standard deviation s if the approximation pnorm(a, avg, s) holds for all values of a. If we are willing to use the normal approximation for height, we can estimate the distribution simply from the mean and standard deviation of our values. If we treat the height data as discrete rather than categorical, we see that the data are not very useful because integer values are more common than expected due to rounding. This is called discretization. With rounded data, the normal approximation is particularly useful when computing probabilities of intervals of length 1 that include exactly one integer.","title":"The Normal CDF and pnorm"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#quantiles","text":"Quantiles are cutoff points that divide a dataset into intervals with set probabilities. The q th quantile is the value at which q % of the observations are equal to or less than that value. You can use the quantile() function to compute quantiles. #Given a dataset data and desired quantile q, you can find the qth quantile of data with: quantile ( data , q )","title":"Quantiles"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#percentiles","text":"Percentiles are the quantiles that divide a dataset into 100 intervals each with 1% probability. You can determine all percentiles of a dataset data like this: p <- seq ( 0.01 , 0.99 , 0.01 ) quantile ( data , p )","title":"Percentiles"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#quartiles","text":"Quartiles divide a dataset into 4 parts each with 25% probability. They are equal to the 25th, 50th and 75th percentiles. The 25th percentile is also known as the 1st quartile, the 50th percentile is also known as the median, and the 75th percentile is also known as the 3rd quartile. The summary() function returns the minimum, quartiles and maximum of a vector.","title":"Quartiles"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#examples","text":"library ( dslabs ) data ( heights ) #Use summary() on the heights$height variable to find the quartiles: summary ( heights $ height ) #Find the percentiles of heights$height: p <- seq ( 0.01 , 0.99 , 0.01 ) percentiles <- quantile ( heights $ height , p ) #Confirm that the 25th and 75th percentiles match the 1st and 3rd quartiles. Note that quantile() returns a named vector. You can access the 25th and 75th percentiles like this (adapt the code for other percentile values): percentiles [ names ( percentiles ) == \"25%\" ] percentiles [ names ( percentiles ) == \"75%\" ]","title":"Examples"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#finding-quantiles-with-qnorm","text":"The qnorm() function gives the theoretical value of a quantile with probability p of observing a value equal to or less than that quantile value given a normal distribution with mean mu and standard deviation sigma: qnorm ( p , mu , sigma ) By default, mu = 0 and sigma = 1.","title":"Finding quantiles with qnorm()"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#relation-to-pnorm","text":"The pnorm() function gives the probability that a value from a standard normal distribution will be less than or equal to a z-score value z. Consider: pnorm(-1.96) ~= 0.025 The result of pnorm() is the quantile. Note that: qnorm(0.025) ~= -1.96 qnorm() and pnorm() are inverse functions: pnorm(qnorm(0.025)) = 0.025","title":"Relation to pnorm"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#quantile-quantile-plots","text":"Quantile-quantile plots, or QQ-plots, are used to check whether distributions are well-approximated by a normal distribution. We start by defining a series of proportion, for example, p equals 0.05, 0.10, 0.15, up to 0.95. Once this is defined for each p, we determine the value q, so that the proportion of the values in the data below q is p. The q's are referred to as the quantiles. Now we will apply this, to out male heights dataset. 5.Q-Q plots Here, you can see that our data points almost fit a straight line. This futher establishes the fact that our data is well suited as a normal distribution with certain parameters.","title":"Quantile-Quantile Plots"},{"location":"Data%20Visualization/01%20-%20Intro%20to%20visualization%20and%20distributions/#boxplots","text":"When data do not follow a normal distribution and cannot be succinctly summarized by only the mean and standard deviation, an alternative is to report a five-number summary: range (ignoring outliers) and the quartiles (25th, 50th, 75th percentile). In a boxplot, the box is defined by the 25th and 75th percentiles and the median is a horizontal line through the box. The whiskers show the range excluding outliers, and outliers are plotted separately as individual points. The interquartile range is the distance between the 25th and 75th percentiles. Boxplots are particularly useful when comparing multiple distributions.","title":"Boxplots"},{"location":"Data%20Visualization/02%20-%20ggplot2/","text":"ggplot Keep this cheat sheet handy R-Cheatsheet We will go through ggplot, by making a plot, piece by piece First, we start off by importing the required libraries #Tidyverse includes ggplot and dplyr along with some more useful libraries library ( tidyverse ) library ( dslabs ) data ( murders ) Next, we have to associate a ggplot object with a data set. This can be done in the following ways #Assuming your data set is 'x' ggplot ( data = x ) ggplot ( x ) x %>% ggplot () #You can use any one command to initializse the object After this is done, a graphics will be rendered. A blank one. One more way we can effectively use ggplot is by assiging plots to variables. Take a look at this code p <- ggplot ( data = x ) print ( p ) #now by printing 'p', you can see a blank graphics being rendered. Layers In ggplot, graphs are created by adding layers Layers can define geometries, compute statistics and more. In general, the syntax of plotting with layers will look something like this data %>% ggplot() + LAYER1 + LAYER2 +..... Usually, the first layer, defines the geometry of the plot. Lets try to do a scatter plot Looking at the docs, we get to know that for a scatter plot, its geom_point() Further the docs say that it can take in multiple args. To actually plot anything, we have to use something called aem() (asthetic mapping). This is the function that connects the data to the plot. # add points layer to predefined ggplot object p <- ggplot ( data = murders ) #adding a layer, look at the usage of the aes() p + geom_point ( aes ( population / 10 ^ 6 , total )) #Output will be a plot Now we will add a layer, that will label each point. For this we have to use geom_text() layer. p + geom_point ( aes ( population / 10 ^ 6 , total )) + # add text layer to scatterplot #Note that you define the label inside of the aes(). This is what ggplot needs geom_text ( aes ( population / 10 ^ 6 , total , label = abb )) geom_text() and geom_label() add text to a scatterplot and require x, y, and label aesthetic mappings. To determine which aesthetic mappings are required for a geometry, read the help file for that geometry. You can add layers with different aesthetic mappings to the same graph. Tweaking our plot further #Setting the size of the points p + geom_point ( aes ( population / 10 ^ 6 , total ), size = 3 ) + # move text labels slightly to the right geom_text ( aes ( population / 10 ^ 6 , total , label = abb ), nudge_x = 1 ) We can simplify this further by using global asthetic mapping. What we do is, when creating the object, we can specify the aesthetic mappings. Then add layers as shown below. # simplify code by adding global aesthetic p <- murders %>% ggplot ( aes ( population / 10 ^ 6 , total , label = abb )) p + geom_point ( size = 3 ) + geom_text ( nudge_x = 1.5 ) # local aesthetics override global aesthetics p + geom_point ( size = 3 ) + #Here, we are assigning a local aesthetic to the text layer, which overrides the global aesthetic geom_text ( aes ( x = 10 , y = 800 , label = \"Hello there!\" )) Scale By default, ggplot scales the data to fit the plot. But in this case, we need a log plot. Lets do that Convert the x-axis to log scale with scale_x_continuous(trans = \"log10\") or scale_x_log10(). Similar functions exist for the y-axis. #Converting to log scale # log base 10 scale the x-axis and y-axis p + geom_point ( size = 3 ) + geom_text ( nudge_x = 0.05 ) + scale_x_continuous ( trans = \"log10\" ) + scale_y_continuous ( trans = \"log10\" ) # efficient log scaling of the axes p + geom_point ( size = 3 ) + #Since the plot is smaller, we use a smaller nudge geom_text ( nudge_x = 0.075 ) + #Here is the short method of the same scale scale_x_log10 () + scale_y_log10 () Since log_10 is a really common scale, ggplot has a predifined scale called scale_x_log10() and scale_y_log10() to make it easier. Labels and Titles Add axis titles with xlab() and ylab() functions. Add a plot title with the ggtitle() function. Lets see an example #We are using the previous plot p + geom_point ( size = 3 ) + geom_text ( nudge_x = 0.075 ) + scale_x_log10 () + scale_y_log10 () + #X-axis label xlab ( \"Population in millions (log scale)\" ) + #Y-axis label ylab ( \"Total number of murders (log scale)\" ) + #Plot title ggtitle ( \"US Gun Murders in 2010\" ) Coloring the plot Coloring the plot is done usually by passing an argument within the layer you want to colour. ... ... # make all points blue p + geom_point ( size = 3 , color = \"blue\" ) # color points by region p + geom_point ( aes ( col = region ), size = 3 ) ... ... Drawing a line Now we will try to add a line, that will show the average murder rate of the dataset. # define average murder rate r <- murders %>% summarize ( rate = sum ( total ) / sum ( population ) * 10 ^ 6 ) %>% pull ( rate ) # basic line with average murder rate for the country p <- p + geom_point ( aes ( col = region ), size = 3 ) + geom_abline ( intercept = log10 ( r )) # slope is default of 1 # change line to dashed and dark grey, line under points p + geom_abline ( intercept = log10 ( r ), lty = 2 , color = \"darkgrey\" ) + geom_point ( aes ( col = region ), size = 3 ) Additonal Touches The style of a ggplot graph can be changed using the theme() function. The ggthemes package adds additional themes. Sometimes, when adding labels, they might overlap with other labels. To avoid this, we use a layer named geom_text_repel() provided by ggrepel library. You can now look at the complete plot here - Complete Plot Other plots in ggplot Histograms Histogram's layer is geom_histogram() # load heights data library ( tidyverse ) library ( dslabs ) data ( heights ) # define p p <- heights %>% filter ( sex == \"Male\" ) %>% ggplot ( aes ( x = height )) # basic histograms p + geom_histogram () p + geom_histogram ( binwidth = 1 ) # histogram with blue fill, black outline, labels and title p + geom_histogram ( binwidth = 1 , fill = \"blue\" , col = \"black\" ) + xlab ( \"Male heights in inches\" ) + ggtitle ( \"Histogram\" ) Smooth density plots library ( tidyverse ) library ( dslabs ) data ( heights ) # define p p <- heights %>% filter ( sex == \"Male\" ) %>% ggplot ( aes ( x = height )) p + geom_density () p + geom_density ( fill = \"blue\" ) Quantile-quantile plots library ( tidyverse ) library ( dslabs ) data ( heights ) # basic QQ-plot p <- heights %>% filter ( sex == \"Male\" ) %>% ggplot ( aes ( sample = height )) p + geom_qq () # QQ-plot against a normal distribution with same mean/sd as data params <- heights %>% filter ( sex == \"Male\" ) %>% summarize ( mean = mean ( height ), sd = sd ( height )) p + geom_qq ( dparams = params ) + geom_abline () # QQ-plot of scaled data against the standard normal distribution heights %>% ggplot ( aes ( sample = scale ( height ))) + geom_qq () + geom_abline ()","title":"ggplot"},{"location":"Data%20Visualization/02%20-%20ggplot2/#ggplot","text":"Keep this cheat sheet handy R-Cheatsheet We will go through ggplot, by making a plot, piece by piece First, we start off by importing the required libraries #Tidyverse includes ggplot and dplyr along with some more useful libraries library ( tidyverse ) library ( dslabs ) data ( murders ) Next, we have to associate a ggplot object with a data set. This can be done in the following ways #Assuming your data set is 'x' ggplot ( data = x ) ggplot ( x ) x %>% ggplot () #You can use any one command to initializse the object After this is done, a graphics will be rendered. A blank one. One more way we can effectively use ggplot is by assiging plots to variables. Take a look at this code p <- ggplot ( data = x ) print ( p ) #now by printing 'p', you can see a blank graphics being rendered.","title":"ggplot"},{"location":"Data%20Visualization/02%20-%20ggplot2/#layers","text":"In ggplot, graphs are created by adding layers Layers can define geometries, compute statistics and more. In general, the syntax of plotting with layers will look something like this data %>% ggplot() + LAYER1 + LAYER2 +..... Usually, the first layer, defines the geometry of the plot. Lets try to do a scatter plot Looking at the docs, we get to know that for a scatter plot, its geom_point() Further the docs say that it can take in multiple args. To actually plot anything, we have to use something called aem() (asthetic mapping). This is the function that connects the data to the plot. # add points layer to predefined ggplot object p <- ggplot ( data = murders ) #adding a layer, look at the usage of the aes() p + geom_point ( aes ( population / 10 ^ 6 , total )) #Output will be a plot Now we will add a layer, that will label each point. For this we have to use geom_text() layer. p + geom_point ( aes ( population / 10 ^ 6 , total )) + # add text layer to scatterplot #Note that you define the label inside of the aes(). This is what ggplot needs geom_text ( aes ( population / 10 ^ 6 , total , label = abb )) geom_text() and geom_label() add text to a scatterplot and require x, y, and label aesthetic mappings. To determine which aesthetic mappings are required for a geometry, read the help file for that geometry. You can add layers with different aesthetic mappings to the same graph.","title":"Layers"},{"location":"Data%20Visualization/02%20-%20ggplot2/#tweaking-our-plot-further","text":"#Setting the size of the points p + geom_point ( aes ( population / 10 ^ 6 , total ), size = 3 ) + # move text labels slightly to the right geom_text ( aes ( population / 10 ^ 6 , total , label = abb ), nudge_x = 1 ) We can simplify this further by using global asthetic mapping. What we do is, when creating the object, we can specify the aesthetic mappings. Then add layers as shown below. # simplify code by adding global aesthetic p <- murders %>% ggplot ( aes ( population / 10 ^ 6 , total , label = abb )) p + geom_point ( size = 3 ) + geom_text ( nudge_x = 1.5 ) # local aesthetics override global aesthetics p + geom_point ( size = 3 ) + #Here, we are assigning a local aesthetic to the text layer, which overrides the global aesthetic geom_text ( aes ( x = 10 , y = 800 , label = \"Hello there!\" ))","title":"Tweaking our plot further"},{"location":"Data%20Visualization/02%20-%20ggplot2/#scale","text":"By default, ggplot scales the data to fit the plot. But in this case, we need a log plot. Lets do that Convert the x-axis to log scale with scale_x_continuous(trans = \"log10\") or scale_x_log10(). Similar functions exist for the y-axis. #Converting to log scale # log base 10 scale the x-axis and y-axis p + geom_point ( size = 3 ) + geom_text ( nudge_x = 0.05 ) + scale_x_continuous ( trans = \"log10\" ) + scale_y_continuous ( trans = \"log10\" ) # efficient log scaling of the axes p + geom_point ( size = 3 ) + #Since the plot is smaller, we use a smaller nudge geom_text ( nudge_x = 0.075 ) + #Here is the short method of the same scale scale_x_log10 () + scale_y_log10 () Since log_10 is a really common scale, ggplot has a predifined scale called scale_x_log10() and scale_y_log10() to make it easier.","title":"Scale"},{"location":"Data%20Visualization/02%20-%20ggplot2/#labels-and-titles","text":"Add axis titles with xlab() and ylab() functions. Add a plot title with the ggtitle() function. Lets see an example #We are using the previous plot p + geom_point ( size = 3 ) + geom_text ( nudge_x = 0.075 ) + scale_x_log10 () + scale_y_log10 () + #X-axis label xlab ( \"Population in millions (log scale)\" ) + #Y-axis label ylab ( \"Total number of murders (log scale)\" ) + #Plot title ggtitle ( \"US Gun Murders in 2010\" )","title":"Labels and Titles"},{"location":"Data%20Visualization/02%20-%20ggplot2/#coloring-the-plot","text":"Coloring the plot is done usually by passing an argument within the layer you want to colour. ... ... # make all points blue p + geom_point ( size = 3 , color = \"blue\" ) # color points by region p + geom_point ( aes ( col = region ), size = 3 ) ... ...","title":"Coloring the plot"},{"location":"Data%20Visualization/02%20-%20ggplot2/#drawing-a-line","text":"Now we will try to add a line, that will show the average murder rate of the dataset. # define average murder rate r <- murders %>% summarize ( rate = sum ( total ) / sum ( population ) * 10 ^ 6 ) %>% pull ( rate ) # basic line with average murder rate for the country p <- p + geom_point ( aes ( col = region ), size = 3 ) + geom_abline ( intercept = log10 ( r )) # slope is default of 1 # change line to dashed and dark grey, line under points p + geom_abline ( intercept = log10 ( r ), lty = 2 , color = \"darkgrey\" ) + geom_point ( aes ( col = region ), size = 3 )","title":"Drawing a line"},{"location":"Data%20Visualization/02%20-%20ggplot2/#additonal-touches","text":"The style of a ggplot graph can be changed using the theme() function. The ggthemes package adds additional themes. Sometimes, when adding labels, they might overlap with other labels. To avoid this, we use a layer named geom_text_repel() provided by ggrepel library. You can now look at the complete plot here - Complete Plot","title":"Additonal Touches"},{"location":"Data%20Visualization/02%20-%20ggplot2/#other-plots-in-ggplot","text":"","title":"Other plots in ggplot"},{"location":"Data%20Visualization/02%20-%20ggplot2/#histograms","text":"Histogram's layer is geom_histogram() # load heights data library ( tidyverse ) library ( dslabs ) data ( heights ) # define p p <- heights %>% filter ( sex == \"Male\" ) %>% ggplot ( aes ( x = height )) # basic histograms p + geom_histogram () p + geom_histogram ( binwidth = 1 ) # histogram with blue fill, black outline, labels and title p + geom_histogram ( binwidth = 1 , fill = \"blue\" , col = \"black\" ) + xlab ( \"Male heights in inches\" ) + ggtitle ( \"Histogram\" )","title":"Histograms"},{"location":"Data%20Visualization/02%20-%20ggplot2/#smooth-density-plots","text":"library ( tidyverse ) library ( dslabs ) data ( heights ) # define p p <- heights %>% filter ( sex == \"Male\" ) %>% ggplot ( aes ( x = height )) p + geom_density () p + geom_density ( fill = \"blue\" )","title":"Smooth density plots"},{"location":"Data%20Visualization/02%20-%20ggplot2/#quantile-quantile-plots","text":"library ( tidyverse ) library ( dslabs ) data ( heights ) # basic QQ-plot p <- heights %>% filter ( sex == \"Male\" ) %>% ggplot ( aes ( sample = height )) p + geom_qq () # QQ-plot against a normal distribution with same mean/sd as data params <- heights %>% filter ( sex == \"Male\" ) %>% summarize ( mean = mean ( height ), sd = sd ( height )) p + geom_qq ( dparams = params ) + geom_abline () # QQ-plot of scaled data against the standard normal distribution heights %>% ggplot ( aes ( sample = scale ( height ))) + geom_qq () + geom_abline ()","title":"Quantile-quantile plots"},{"location":"Data%20Visualization/03%20-%20Dplyr/","text":"Dplyr summarize() function This function in R, helps us provide a summary of the data, with more intuitive and readable code. # compute average and standard deviation for males #Use the heights dataset s <- heights %>% #Filter only male filter ( sex == \"Male\" ) %>% #Using summarize to summerize. Note that we can use custom column names for the output. summarize ( average = mean ( height ), standard_deviation = sd ( height )) The result is stored in a data frame. Thus allowing us to access the elemnts with the $ operator. # access average and standard deviation from summary table s $ average s $ standard_deviation summarize() can compute any summary function that operates on vectors and returns a single value, but it cannot operate on functions that return multiple values. Like most dplyr functions, summarize() is aware of variable names within data frames and can use them directly. Usually, most of the dplyr functions return data frames. The dot operator allows dplyr functions to return single vectors or numbers instead of only data frames. us_murder_rate %>% .$rate is equivalent to us_murder_rate$rate . Group By Dplyr functions act differently when we use it against a grouped dataframe. Lets see an example heights %>% group_by ( sex ) Here, you are grouping the heights dataframe by sex. Now when trying to summarize that data. > heights %>% + group_by ( sex ) %>% + summarize ( average = mean ( height ), standard_deviation = sd ( height )) # A tibble: 2 \u00d7 3 sex average standard_deviation < fct > < dbl > < dbl > 1 Female 64.9 3.76 2 Male 69.3 3.61 Sorting The arrange() function from dplyr sorts a data frame by a given column. # arrange by population column, smallest to largest murders %>% arrange ( population ) %>% head () # arrange by murder rate in descending order murders %>% arrange ( desc ( murder_rate )) %>% head () We can sort based on multiple columns like this # arrange by region alphabetically, then by murder rate within each region murders %>% arrange ( region , murder_rate ) %>% head () We can show the top/bottom n rows like this # show the top 10 states with highest murder rate, not ordered by rate murders %>% top_n ( 10 , murder_rate ) # show the top 10 states with highest murder rate, ordered by rate murders %>% arrange ( desc ( murder_rate )) %>% top_n ( 10 ) # alternatively, can use the slice_max function murders %>% slice_max ( murder_rate , n = 10 )","title":"Dplyr"},{"location":"Data%20Visualization/03%20-%20Dplyr/#dplyr","text":"","title":"Dplyr"},{"location":"Data%20Visualization/03%20-%20Dplyr/#summarize-function","text":"This function in R, helps us provide a summary of the data, with more intuitive and readable code. # compute average and standard deviation for males #Use the heights dataset s <- heights %>% #Filter only male filter ( sex == \"Male\" ) %>% #Using summarize to summerize. Note that we can use custom column names for the output. summarize ( average = mean ( height ), standard_deviation = sd ( height )) The result is stored in a data frame. Thus allowing us to access the elemnts with the $ operator. # access average and standard deviation from summary table s $ average s $ standard_deviation summarize() can compute any summary function that operates on vectors and returns a single value, but it cannot operate on functions that return multiple values. Like most dplyr functions, summarize() is aware of variable names within data frames and can use them directly. Usually, most of the dplyr functions return data frames. The dot operator allows dplyr functions to return single vectors or numbers instead of only data frames. us_murder_rate %>% .$rate is equivalent to us_murder_rate$rate .","title":"summarize() function"},{"location":"Data%20Visualization/03%20-%20Dplyr/#group-by","text":"Dplyr functions act differently when we use it against a grouped dataframe. Lets see an example heights %>% group_by ( sex ) Here, you are grouping the heights dataframe by sex. Now when trying to summarize that data. > heights %>% + group_by ( sex ) %>% + summarize ( average = mean ( height ), standard_deviation = sd ( height )) # A tibble: 2 \u00d7 3 sex average standard_deviation < fct > < dbl > < dbl > 1 Female 64.9 3.76 2 Male 69.3 3.61","title":"Group By"},{"location":"Data%20Visualization/03%20-%20Dplyr/#sorting","text":"The arrange() function from dplyr sorts a data frame by a given column. # arrange by population column, smallest to largest murders %>% arrange ( population ) %>% head () # arrange by murder rate in descending order murders %>% arrange ( desc ( murder_rate )) %>% head () We can sort based on multiple columns like this # arrange by region alphabetically, then by murder rate within each region murders %>% arrange ( region , murder_rate ) %>% head () We can show the top/bottom n rows like this # show the top 10 states with highest murder rate, not ordered by rate murders %>% top_n ( 10 , murder_rate ) # show the top 10 states with highest murder rate, ordered by rate murders %>% arrange ( desc ( murder_rate )) %>% top_n ( 10 ) # alternatively, can use the slice_max function murders %>% slice_max ( murder_rate , n = 10 )","title":"Sorting"},{"location":"Data%20Visualization/04%20-%20Case%20Study/","text":"Case Study: Trends in World Health and Economics We will look at a case study involving data from the Gapminder Foundation about trends in world health and economics. The dataset The gapmider dataset can be found here # load and inspect gapminder data library ( dslabs ) data ( gapminder ) head ( gapminder ) Now, we will explore new concepts, as we dig this data Faceting Faceting makes multiple side-by-side plots stratified by some variable. This is a way to ease comparisons. facet_grid() The facet_grid() function allows faceting by up to two variables, with rows faceted by one variable and columns faceted by the other variable. To facet by only one variable, use the dot operator as the other variable. # facet by continent and year filter ( gapminder , year %in% c ( 1962 , 2012 )) %>% ggplot ( aes ( fertility , life_expectancy , col = continent )) + geom_point () + facet_grid ( continent ~ year ) What we just made is, a grid of plots (fertility vs life expectancy) for each continent, for each year. You can take a look at ouptut for a better understanding. Assume we want to compare just the overall trends in life expectancy, instad of making a grid of plots. We use the . for it. Look at this example. # facet by year only filter ( gapminder , year %in% c ( 1962 , 2012 )) %>% ggplot ( aes ( fertility , life_expectancy , col = continent )) + geom_point () + facet_grid ( . ~ year ) facet_wrap() The facet_wrap() function facets by one variable and automatically wraps the series of plots so they have readable dimensions. # facet by year, plots wrapped onto multiple rows years <- c ( 1962 , 1980 , 1990 , 2000 , 2012 ) continents <- c ( \"Europe\" , \"Asia\" ) gapminder %>% filter ( year %in% years & continent %in% continents ) %>% ggplot ( aes ( fertility , life_expectancy , col = continent )) + geom_point () + facet_wrap ( ~ year ) Time Series Plots Time series plots have time on the x-axis and a variable of interest on the y-axis. Scatter plot #Take dataset gapmider gapminder %>% #Pipe it into filter and filter US filter ( country == \"United States\" ) %>% #Pipe it into ggplot, and use year and fertility as x and y ggplot ( aes ( year , fertility )) + #Use scatter plot geom_point ( na.rm = TRUE ) Line graph # line plot of US fertility by year gapminder %>% filter ( country == \"United States\" ) %>% ggplot ( aes ( year , fertility )) + geom_line ( na.rm = TRUE ) Multiple Time Series Here, we will ideally want each series to be its own line, in a different line. For this, we will use aes to automatically colour based on countries. # fertility time series for two countries - lines colored by country #Select Countries countries <- c ( \"South Korea\" , \"Germany\" ) #Filter those countries from the dataset gapminder %>% filter ( country %in% countries ) %>% #Using aes to select year and fertility, and colour it ggplot ( aes ( year , fertility , col = country )) + #Plot it geom_line () Adding Labels # life expectancy time series - lines colored by country and labeled, no legend #Create a data frame labes, with the labels we actually need (here 2 countries) labels <- data.frame ( country = countries , x = c ( 1975 , 1965 ), y = c ( 60 , 72 )) #Filter the dataset gapminder %>% filter ( country %in% countries ) %>% #Using aes to select year and life_expectancy, and colour it ggplot ( aes ( year , life_expectancy , col = country )) + #Plot it geom_line () + #Add the labels geom_text ( data = labels , aes ( x , y , label = country ), size = 5 ) + #No legend theme ( legend.position = \"none\" ) Transformations Log transformations convert multiplicative changes into additive changes. Common transformations are the log base 2 transformation and the log base 10 transformation. The choice of base depends on the range of the data. The natural log is not recommended for visualization because it is difficult to interpret. Normal histogram will look something like this # histogram of dollars per day #Set year variable past_year <- 1970 gapminder %>% #Filter year, and non-NA data filter ( year == past_year & ! is.na ( gdp )) %>% #Ask aes to give ggplot the required data ggplot ( aes ( dollars_per_day )) + #Make histogram geom_histogram ( binwidth = 1 , color = \"black\" ) Now, lets apply log 2 transformation to the plot, and see how it turns out. # repeat histogram with log2 scaled data gapminder %>% filter ( year == past_year & ! is.na ( gdp )) %>% #Look the log2 function ggplot ( aes ( log2 ( dollars_per_day ))) + geom_histogram ( binwidth = 1 , color = \"black\" ) Scale the x-axis using scale_x_continuous() or scale_x_log10() layers in ggplot2. Similar functions exist for the y-axis. Stratify and Boxplot Make boxplots stratified by a categorical variable using the geom_boxplot() geometry. Rotate axis labels by changing the theme through element_text() . You can change the angle and justification of the text labels. The reorder function We can use this function to reorder the categories in a dataset. In this example, we will sort the regions based on mean of each region. This will make sense, when you compare the previous boxplot and this one. # by default, factor order is alphabetical fac <- factor ( c ( \"Asia\" , \"Asia\" , \"West\" , \"West\" , \"West\" )) levels ( fac ) # reorder factor by the category means value <- c ( 10 , 11 , 12 , 6 , 4 ) fac <- reorder ( fac , value , FUN = mean ) levels ( fac ) Run this code to see the result. 5. Boxplots.R","title":"Case Study: Trends in World Health and Economics"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#case-study-trends-in-world-health-and-economics","text":"We will look at a case study involving data from the Gapminder Foundation about trends in world health and economics.","title":"Case Study: Trends in World Health and Economics"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#the-dataset","text":"The gapmider dataset can be found here # load and inspect gapminder data library ( dslabs ) data ( gapminder ) head ( gapminder ) Now, we will explore new concepts, as we dig this data","title":"The dataset"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#faceting","text":"Faceting makes multiple side-by-side plots stratified by some variable. This is a way to ease comparisons.","title":"Faceting"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#facet_grid","text":"The facet_grid() function allows faceting by up to two variables, with rows faceted by one variable and columns faceted by the other variable. To facet by only one variable, use the dot operator as the other variable. # facet by continent and year filter ( gapminder , year %in% c ( 1962 , 2012 )) %>% ggplot ( aes ( fertility , life_expectancy , col = continent )) + geom_point () + facet_grid ( continent ~ year ) What we just made is, a grid of plots (fertility vs life expectancy) for each continent, for each year. You can take a look at ouptut for a better understanding. Assume we want to compare just the overall trends in life expectancy, instad of making a grid of plots. We use the . for it. Look at this example. # facet by year only filter ( gapminder , year %in% c ( 1962 , 2012 )) %>% ggplot ( aes ( fertility , life_expectancy , col = continent )) + geom_point () + facet_grid ( . ~ year )","title":"facet_grid()"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#facet_wrap","text":"The facet_wrap() function facets by one variable and automatically wraps the series of plots so they have readable dimensions. # facet by year, plots wrapped onto multiple rows years <- c ( 1962 , 1980 , 1990 , 2000 , 2012 ) continents <- c ( \"Europe\" , \"Asia\" ) gapminder %>% filter ( year %in% years & continent %in% continents ) %>% ggplot ( aes ( fertility , life_expectancy , col = continent )) + geom_point () + facet_wrap ( ~ year )","title":"facet_wrap()"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#time-series-plots","text":"Time series plots have time on the x-axis and a variable of interest on the y-axis. Scatter plot #Take dataset gapmider gapminder %>% #Pipe it into filter and filter US filter ( country == \"United States\" ) %>% #Pipe it into ggplot, and use year and fertility as x and y ggplot ( aes ( year , fertility )) + #Use scatter plot geom_point ( na.rm = TRUE ) Line graph # line plot of US fertility by year gapminder %>% filter ( country == \"United States\" ) %>% ggplot ( aes ( year , fertility )) + geom_line ( na.rm = TRUE )","title":"Time Series Plots"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#multiple-time-series","text":"Here, we will ideally want each series to be its own line, in a different line. For this, we will use aes to automatically colour based on countries. # fertility time series for two countries - lines colored by country #Select Countries countries <- c ( \"South Korea\" , \"Germany\" ) #Filter those countries from the dataset gapminder %>% filter ( country %in% countries ) %>% #Using aes to select year and fertility, and colour it ggplot ( aes ( year , fertility , col = country )) + #Plot it geom_line ()","title":"Multiple Time Series"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#adding-labels","text":"# life expectancy time series - lines colored by country and labeled, no legend #Create a data frame labes, with the labels we actually need (here 2 countries) labels <- data.frame ( country = countries , x = c ( 1975 , 1965 ), y = c ( 60 , 72 )) #Filter the dataset gapminder %>% filter ( country %in% countries ) %>% #Using aes to select year and life_expectancy, and colour it ggplot ( aes ( year , life_expectancy , col = country )) + #Plot it geom_line () + #Add the labels geom_text ( data = labels , aes ( x , y , label = country ), size = 5 ) + #No legend theme ( legend.position = \"none\" )","title":"Adding Labels"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#transformations","text":"Log transformations convert multiplicative changes into additive changes. Common transformations are the log base 2 transformation and the log base 10 transformation. The choice of base depends on the range of the data. The natural log is not recommended for visualization because it is difficult to interpret. Normal histogram will look something like this # histogram of dollars per day #Set year variable past_year <- 1970 gapminder %>% #Filter year, and non-NA data filter ( year == past_year & ! is.na ( gdp )) %>% #Ask aes to give ggplot the required data ggplot ( aes ( dollars_per_day )) + #Make histogram geom_histogram ( binwidth = 1 , color = \"black\" ) Now, lets apply log 2 transformation to the plot, and see how it turns out. # repeat histogram with log2 scaled data gapminder %>% filter ( year == past_year & ! is.na ( gdp )) %>% #Look the log2 function ggplot ( aes ( log2 ( dollars_per_day ))) + geom_histogram ( binwidth = 1 , color = \"black\" ) Scale the x-axis using scale_x_continuous() or scale_x_log10() layers in ggplot2. Similar functions exist for the y-axis.","title":"Transformations"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#stratify-and-boxplot","text":"Make boxplots stratified by a categorical variable using the geom_boxplot() geometry. Rotate axis labels by changing the theme through element_text() . You can change the angle and justification of the text labels.","title":"Stratify and Boxplot"},{"location":"Data%20Visualization/04%20-%20Case%20Study/#the-reorder-function","text":"We can use this function to reorder the categories in a dataset. In this example, we will sort the regions based on mean of each region. This will make sense, when you compare the previous boxplot and this one. # by default, factor order is alphabetical fac <- factor ( c ( \"Asia\" , \"Asia\" , \"West\" , \"West\" , \"West\" )) levels ( fac ) # reorder factor by the category means value <- c ( 10 , 11 , 12 , 6 , 4 ) fac <- reorder ( fac , value , FUN = mean ) levels ( fac ) Run this code to see the result. 5. Boxplots.R","title":"The reorder function"}]}